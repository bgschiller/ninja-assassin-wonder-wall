\documentclass[12pt]{article}



    \usepackage{clrscode3e}

    \usepackage[parfill]{parskip}
    \usepackage{amsmath,amsthm,amssymb}
    \usepackage{latexsym} %gives nice \leadsto
    \newtheorem*{lem}{Lemma}
    \newtheorem*{thm}{Theorem}
    \newtheorem*{definition}{Definition}

    \DeclareMathOperator{\w}{w}
    \DeclareMathOperator{\n}{n}
    \DeclareMathOperator{\pairs}{pairs}
    \usepackage{moreverb}
    \usepackage{color}

    \usepackage{multicol}
    \usepackage{pstricks}
    \usepackage{auto-pst-pdf}
    \usepackage[margin=1.5in]{geometry}
    \usepackage{moreverb}
    \usepackage{listings}
    \usepackage{color}

    \definecolor{mygreen}{rgb}{0,0.5,0}
    \definecolor{mygray}{rgb}{0.5,0.5,0.5}
    \definecolor{mymauve}{rgb}{0.58,0,0.82}


    \title{The Ninja Assassin Wonderwall Game}
    \author{Brian Schiller \\ { advised by Dr. Tilmann Glimm}}
    \date{Spring 2013}


\begin{document}
\maketitle

\tableofcontents

\section{Introduction}
    Ninja Assassin Wonderwall is a game played at summer camps, sometimes under the name `Eclipse'. It is played with as few as 4 players, though it is better with ten or more. To play, each player chooses two other players (without indicating their choices), one to be their ninja assassin and the other to be their wonderwall. When the game starts, every player tries to keep their wonderwall between themself and their ninja assassin.

    Camp counselors who organize the game can usually expect it to last until campers grow bored or it is called off. But occasionally the running players will slow down... and stop. Every player finds themselves on the safe side of their wonderwall, protected from their ninja assassin. We call this scenario a solution, which will be more precisely defined in the next section.

    In the small example below, every player is in a position that satisfies their constraints--they are on a line with their ninja assassin and wonderwall with the wonderwall in the middle. The player's choices are displayed in a relationship table. Each row of the table shows a player, that player's wonderwall, and that player's ninja assassin.

    \begin{center} %6 player example game
        \begin{multicols}{2}
            \begin{pspicture}(0,0)(10,10)
                \qdisk(0,1){2pt}
                \uput[u](0,1){C}

                \qdisk(-0.4,2){2pt}
                \uput[u](-0.4,2){E}

                \qdisk(1,2){2pt}
                \uput[u](1,2){B}

                \qdisk(2,3){2pt}
                \uput[u](2,3){A}

                \qdisk(2.4,2){2pt}
                \uput[u](2.4,2){D}

                \qdisk(3.5,2){2pt}
                \uput[u](3.5,2){F}
            \end{pspicture}

            \columnbreak

            \begin{tabular}{l | c | c}
                $p$ & $\w(p)$ & $\n(p)$ \\
                \hline
                A &  B& C\\
                B &  D& F\\
                C &  B& A\\
                D &  B& E\\
                E &  D& F\\
                F &  D& B
            \end{tabular}
         \end{multicols}
    \end{center}

    Looking at that solution, it seems like we could grab players $A$ and $C$ and pivot them around $B$, putting all the players on a line. But can we always reduce a solution to a single dimension? It seems like the extra freedom in higher dimensions might allow new solutions that don't appear on the real line.

    In fact, we will see that if a game has a solution in $\mathbb{R}^n$ it must also have a solution on the real line. This means that campers need not dig holes and climb trees in order to produce a solution. The result also says that in searching for solutions we can restrict our search to linear orderings of the players.

    Not every game has a solution. Below are two four-player games, one with a solution and one without.
    \newpage
    \begin{center} %4 player games
        \begin{multicols}{2} %solved game
            \begin{pspicture}(-5,-5)(5,5)
                \qdisk(0,0){2pt}
                \uput[u](0,0){A}

                \qdisk(1,0){2pt}
                \uput[u](1,0){B}

                \qdisk(2,0){2pt}
                \uput[u](2,0){C}

                \qdisk(3,0){2pt}
                \uput[u](3,0){D}
            \end{pspicture} 

            \columnbreak
            
            \begin{tabular}{ l | c | c}
                 $p$ & $\w(p)$ & $\n(p)$ \\
                 \hline
                  A &  B& C\\
                  B &  C& D\\
                  C &  B& A\\
                  D &  B& A\\
            \end{tabular}
        \end{multicols}
        \vspace{24pt}
        \begin{multicols}{2} %unsolvable game
            \begin{pspicture}(-5,-5)(5,5)
                \qdisk(-1,0){2pt}
                \uput[u](-1,0){A}

                \qdisk(1,0){2pt}
                \uput[u](1,0){C}

                \qdisk(0,1){2pt}
                \uput[u](0,1){B}

                \qdisk(0,-1){2pt}
                \uput[u](0,-1){D}
            \end{pspicture}

            \columnbreak
            
            \begin{tabular}{l | c | c}
                $p$ & $\w(p)$ & $\n(p)$ \\
                \hline
                A & B& C\\
                B & D& A\\
                C & B& A\\
                D & B& A
            \end{tabular}
        \end{multicols}
    \end{center}
    How can we tell from the relationship table whether or not a game has a solution? Since it is sufficient to search the orderings of players, we could simply try every permutation of the players. This proves to be too computationally expensive. We will explore another algorithm, based on finding cycles in directed graphs, that will be considerably faster. We will also give a recipe for transforming an instance of a ninja assassin wonderwall game into an instance of a Boolean Satisfiability problem.


\section{Definitions}

    \begin{definition}
    A \emph{Ninja Assassin Wonderwall problem} is a set $P$ together with two functions $\w:P\to P, \quad \n: P\to P$ that satisfy $\w(p) \neq p, \n(p) \neq p, \text{ and } \w(p) \neq \n(p)$ for all $p \in P$.
    \end{definition}

    Here, the $\w(p)$ and $\n(p)$ represent the wonderwall and ninja assassin, respectively, of a player $p$. The restrictions on the functions ensure that no player may choose themselves as either role or choose the same person for both roles. 


    \begin{definition}
    A \emph{solution} to a Ninja Assassin Wonderwall problem is a function $S: P\to \mathbb{R}^{n}$ such that:
        \begin{enumerate}
        \item $S$ is one-to-one (two players may not occupy the same space)
        \item For each $p \in P$, $S(\w(p))$ lies on the line segment between $S(p)$ and $S(\n(p))$.
        \end{enumerate}
    \end{definition}


\section{Reduction to one dimension}

    It seems as though the extra freedom in higher dimensions might allow solutions to games that are unsolvable on the real line. A camp counselor might be tempted to have campers climb trees or stand on one another's shoulders in search of a solution. Perhaps surprisingly, this is unnecessary. Any game that is solvable in $\mathbb{R}^n$ is solvable in $\mathbb{R}$.


    \begin{thm}
    Any Ninja Assassin Wonderwall game which has a solution in $n$ dimensions ($n > 1$) has a solution in $n-1$ dimensions.
    \end{thm}
    \begin{proof}
    Suppose we have a game that has a solution in $\mathbb{R}^n$. That is, we have a one-to-one function $S: P \to \mathbb{R}^n$ such that for each $p \in P$, $p$'s wonderwall lies on the line segment between $p$'s ninja assassin and $p$. 

    Consider the set $L$ of all lines in $\mathbb{R}^n$ which go through two or more points in the image of $P$ under $S$. Since there are $\lvert P \rvert$ points, there are no more than $\binom{ \lvert P \rvert}{2}$ such lines. 

    Now consider an $n-1$-dimensional hyperplane $\Pi$ through the origin that is not perpendicular to any line in $L$. Since each line is perpendicular to exactly one hyperplane, and $\lvert L \rvert \leq \binom{\lvert P \rvert}{2}$, which is finite, such a hyperplane exists. (There are uncountably many $n-1$-dimensional hyperplanes through the origin).

    Form a new solution, $S'$ by mapping each player $p\in P$ to the projection onto $\Pi$. By construction, $\Pi$ is not perpendicular to any line in $L$, so each player's position is distinct. Since projection onto a plane through the origin is a linear transformation, linear relationships are preserved. In particular, the linear relationships which put every player's wonderwall on the line segment between that player and their ninja assassin. So $S'$ is a solution in $n-1$ dimensions.
    \end{proof}
    \begin{center}
    \begin{tabular}{r c l}
    {%
    \begin{pspicture}(0,0)(10,10)
        %Future locations
        %(included to maintain scale with other picture)
        %(plotted first, in white, to be covered over)
        \uput[d](0,0){\color{white}{C}}
        \uput[d](-0.4,0){\color{white}{E}}
        \uput[d](1,0){\color{white}{B}}
        \uput[d](2,0){\color{white}{A}}
        \uput[d](2.4,0){\color{white}{D}}
        \uput[d](3.5,0){\color{white}{F}}  


        %players and labels
        \qdisk(0,1){2pt}
        \uput[u](0,1){C}

        \qdisk(-0.4,2){2pt}
        \uput[u](-0.4,2){E}

        \qdisk(1,2){2pt}
        \uput[u](1,2){B}

        \qdisk(2,3){2pt}
        \uput[u](2,3){A}

        \qdisk(2.4,2){2pt}
        \uput[u](2.4,2){D}

        \qdisk(3.5,2){2pt}
        \uput[u](3.5,2){F}

        %the set L
        \psline[linestyle=dotted](-0.5,0.5)(2.5,3.5) %CBA
        \psline[linestyle=dotted](-1,2)(4,2) %EBDF

        \psline[linestyle=dotted](1.7,3.75)(2.7,1.25) %AD
        \psline[linestyle=dotted](1.6,3.26666)(3.9,1.7333) %AF
        \psline[linestyle=dotted](-1,1.75)(2.6,3.25) %AE

        \psline[linestyle=dotted](-0.6,2.5)(0.2,0.5) %CE
        \psline[linestyle=dotted](-0.5,0.79166)(3.3,2.375) %CD
        \psline[linestyle=dotted](-0.4,0.8857)(3.9,2.11428) %CF

        %hyperplane Pi
        \psline(-1,0)(4,0)
        \uput[r](4,0){$\Pi$}
    \end{pspicture}} & {%
    \color{white}{project}
    } &{%
    \begin{pspicture}(0,0)(10,10)

        %old locations
        \pscircle[linestyle=dashed](0,1){3pt}
        \uput[u](0,1){C}

        \pscircle[linestyle=dashed](-0.4,2){3pt}
        \uput[u](-0.4,2){E}

        \pscircle[linestyle=dashed](1,2){3pt}
        \uput[u](1,2){B}

        \pscircle[linestyle=dashed](2,3){3pt}
        \uput[u](2,3){A}

        \pscircle[linestyle=dashed](2.4,2){3pt}
        \uput[u](2.4,2){D}

        \pscircle[linestyle=dashed](3.5,2){3pt}
        \uput[u](3.5,2){F}
        
        %lines of projection
        \psline[linestyle=dashed](-0.4,2)(-0.4,0) %E
        \psline[linestyle=dashed](0,1)(0,0) %C
        \psline[linestyle=dashed](1,2)(1,0) %B
        \psline[linestyle=dashed](2,3)(2,0) %A
        \psline[linestyle=dashed](2.4,2)(2.4,0) %D
        \psline[linestyle=dashed](3.5,2)(3.5,0) %F

        %players and labels
        \qdisk(0,0){2pt}
        \uput[d](0,0){C}

        \qdisk(-0.4,0){2pt}
        \uput[d](-0.4,0){E}

        \qdisk(1,0){2pt}
        \uput[d](1,0){B}

        \qdisk(2,0){2pt}
        \uput[d](2,0){A}

        \qdisk(2.4,0){2pt}
        \uput[d](2.4,0){D}

        \qdisk(3.5,0){2pt}
        \uput[d](3.5,0){F}        


        %hyperplane Pi
        \psline(-1,0)(4,0)
        \uput[r](4,0){$\Pi$}
    \end{pspicture}}
    \end{tabular}
    \end{center}

    This theorem, repeated as necessary, shows that if a solution exists in $n>1$ dimensions, a solution exists in one dimension. Thus, if we are looking for solutions, it is enough to consider orderings of players on a line.

\section{Overview: P vs NP}
    P and NP are coarse ways to describe the time required to solve a problem. Often we are a bit cavalier about the distinction between a problem and an \emph{instance} of a problem. However, the difference is important in discussing P vs NP. A problem describes the form of the input and desired output. An instance of a problem is a \emph{specific} input of the form described. 

    Simply put, P is the set of all problems that can be solved in polynomial time. NP is the set of all problems whose solutions can be \emph{verified} in polynomial time. 

    For a simple example, consider the problem of sorting.  Sorting takes a set of $n$ objects for which a total order, $<$ is defined and produces a permutation of those objects $x_1 x_2 x_3 \ldots x_n$ such that $x_i < x_j$ whenever $i < j$. An instance of sorting is `sort the set $\{4, 2 ,1, 5, 8\}$', which would have the solution $\langle 1, 2, 4, 5, 8 \rangle$. 

    It is an open question whether or not the two classes are distinct. That is, does every problem with a polynomial verifier have a polynomial solver? This is known as the P=NP problem.

    To continue the example, one way to solve an instance of a sorting problem is to try every permutation of the $n$ objects, checking each to see whether it is in sorted order. This algorithm would require $O(n\cdot n!)$ time, since there is only one out of $n!$ permutations that is in sorted order, and it takes as many as $n$ steps to determine whether each permutation is sorted. This running time is larger than any polynomial, but this does \emph{not} mean that the problem of sorting is not in P. We have merely failed to show that is in P; we haven't shown that is is \emph{not} in P. In fact, there are algorithms that solve instances of sorting in $O(n^2)$, which is a polynomial, so the sorting problem belongs in P. 

    It is also in NP, since a candidate solution could be verified (or refuted) in polynomial time. One way to verify would be to check that for every pair $x_i, x_{i+1}$, $x_i < x_{i+1}$. Another way would be to just sort the set again (using a polynomial-time algorithm) and check that the new solution matches the candidate. 

    There is a related class of problems, called NP-hard. A problem $Q$ is in NP-hard is every problem $R$ in NP is polynomial reducible to $Q$. That is, given an instance of $R$ we can transform that instance in a polynomial number of steps into an instance of $Q$. We also require that a solution to this new instance of $Q$ produces a solution to the original instance of $R$ in polynomial time.

    There are a number of problems in NP which are also in NP-hard. These problems comprise a class called NP-complete. For instance, the Travelling Salesman Problem, the Knapsack Problem, Subset-Sum, and 3-CNF Satisfiablilty are all in NP-complete. This means that we can take an instance of, say, The Knapsack Problem, and transform it into Subset-Sum in such a way that the new instance has a solution if and only if the old one did. %TODO:perhaps mention decision problems?

    Problems in NP-complete are much studied and the prevailing opinion is that there are no polynomial time solvers for any of them~\cite{clrs}(pg 1050). (If a polynomial-time solver was found for, say Subset-Sum, we could transform and instance from any of the others into an instance of Subset-Sum and BOOM: we've just created a polynomial time solver for the other problem.)

    The typical way to show that a problem is NP-complete is to take an arbitrary instance of a problem that is known to be NP-complete and give a polynomial time recipe to transform that instance into an instance of the problem at hand. Then if a polynomial algorithm exists for the problem at hand, we have created one for the NP-complete problem. 

    If Ninja Assassin Wonderwall were an NP-complete problem, finding a polynomial time solver would be beyond the scope of this project. Unfortunately, I have been unable to either show it is NP-complete or find a polynomial time algorithm. 

\section{Relation to known problems}
    A simple, though possibly inefficient, way to solve a Ninja Assassin Wonderwall problem would be to transform it into an instance of a known problem for which solvers already exist. We will transform an aribitrary Ninja Assassin Wonderwall problem into a Conjunctive Normal Form Satisfiability (CNF SAT) problem.

    Conjunctive Normal Form Satisfiability, or CNF Sat, is a problem whose input is a statement in propositional logic of the form
        \begin{align*} 
                    & (a_1 \vee a_2 \vee \ldots \vee a_{n_a}) \\
            \wedge  & (b_1 \vee b_2 \vee \ldots \vee b_{n_b})\\
            \vdots  &\\
            \wedge  & (x_1 \vee x_2 \vee \ldots \vee x_{n_x})
        \end{align*}
    and whose output is a mapping from each variable in the statement to either true or false such that the statement as a whole is true. 

    We begin with some notation. Let $x_{a,b}$ denote the truth of `player $a$ is left of player $b$'. Then for each row of a relationship table $p$, $\w(p)$, $\n(p)$, we can write
        \begin{align*}
                    & (x_{p_1, \w(p_1)} \Leftrightarrow x_{\w(p_1), \n(p_1)})\\
            \wedge  & (x_{p_2, \w(p_2)} \Leftrightarrow x_{\w(p_2), \n(p_2)})\\
            \vdots  &\\
            \wedge  & (x_{p_n, \w(p_n)} \Leftrightarrow x_{\w(p_n), \n(p_n)})
        \end{align*}

    In order to put our statement in CNF, we will need to convert each of those clauses. For player $i$, we will have 
        \begin{align*}
            & (x_{p_i, \w(p_i)} \Leftrightarrow x_{\w(p_i), \n(p_i)})\\
            \Leftrightarrow & (\lnot x_{p_i, \w(p_i)} \vee x_{\w(p_i), \n(p_i)}) \wedge (x_{p_i, \w(p_i)} \vee \lnot x_{\w(p_i), \n(p_i)})
        \end{align*}

    What we haven't mentioned yet is that there is a big difference between a CNF SAT problem with two variables to a clause (2-SAT), and one with three variables to a clause (3-SAT). Surprisingly, 2-SAT can be solved in linear time but 3-SAT is an NP-Complete problem~\cite{clrs}(pg 1049). That is, no one has found an algorithm that will solve it in polynomial time (and the general sentiment is that none exists).

    So far, so good: we only have two variables to a clause. This looks like it is leading us to a linear time solution. (Actually, since our variables are $x_{p_i, p_j}$, this would be an $O(n^2)$ solution). 

    However, this is not quite enough. In moving to simple boolean values, we have given up the transitive property. As it is now, there is nothing keeping the problem from deciding that $x_{a,b}, x_{b,c}$, and $x_{c,a}$ are all true (even though this wouldn't make sense in the context of a linear solution). One way to think about this is that a solution to the Ninja Assassin Wonderwall problem will always produce a solution to the CNF SAT problem, but not the other way around.

    We will need to add constraints to ensure that we respect transitivity. For every $a,b,c \in P$, we need the condition $(x_{a,b} \wedge x_{b,c}) \Rightarrow x_{a,c}$. This adds quite a bit of bloat to our statement. Specifically, it adds $n(n-1)(n-2)$ expressions of that form, all $\wedge$'d together.

    More important than just increasing the size of our statement, each of these new clauses will contain three variables:
    \begin{align*}
        &(x_{a,b} \wedge x_{b,c}) \Rightarrow x_{a,c} \\
        \Leftrightarrow & (\lnot x_{a,b} \vee \lnot x_{b,c} \vee x_{a,c})
    \end{align*}

    This pushes us squarely into the realm of 3-SAT, where we don't expect to find a polynomial time algorithm to save us. 

    \begin{proof}[A solution to this 3-SAT problem gives a solution to the Ninja Assassin Wonderwall problem]
    Suppose we have solution to this 3-SAT problem. That is, we have a mapping from $\{x_{a,b} \mid a,b \in P\}$ into $\{\const{true}, \const{false}\}$. Does that give a solution to the Ninja Assassin Wonderwall problem? We can interpret the values of $x_{a,b}$ as a strict total order relation, $<$, where $a<b$ if and only if $x_{a,b}$ is true. 

    Let $\sigma$ be the permutation of P that comes from sorting according to this total order. Suppose some player $p$'s constraints are not satisfied by $\sigma$. Then either 
    \begin{align*}
    x_{p,\n(p)} &\wedge x_{\n(p),\w(p)} \text{ or } \\
    x_{\w(p),\n(p)} &\wedge x_{\n(p),p}
    \end{align*}. Without loss of generality, say $x_{p,\n(p)} \wedge x_{\n(p),\w(p)}$. By the transitivity constraints, we must also have $x_{p,\w(p)}$. We know from the first clause of $p$'s constraint that 
    \begin{align*}
        \lnot x_{p_i, \w(p_i)} \vee x_{\w(p_i), \n(p_i)}\\
        \lnot x_{p, \w(p)} &&\text{(since $x_{\n(p),\w(p)}$ is true.)}\\
    \end{align*}
    So we have $\lnot x_{p, \w(p)}$ and $x_{p,\n(p)}$. This is a contradiction, so no such player $p$ can exist.
    \end{proof}

    So this is a possible way to solve Ninja Assassin Wonderwall problems. Another option would be to stop with the 2-SAT problem created by ignoring transitivity constraints. From there, we could ennumerate all solutions, searching for one that respected transitivity. %I've downloaded an article with an algorithm describing the enumeration step of this, but I haven't had a chance to play with it. Probably won't before I turn this in...

    This is very similar to the algorithm explained below, which approaches the problem directly rather than first turning it into an instance into a CNF problem.

\section{Constructive algorithm}
    \label{sec:algorithm}
    Consider a permutation $\sigma$ of the player set $P$. We'd like to know if $\sigma$ is a solution. If that $\sigma$ satisfies player $p$'s constraints, then $\sigma$ must have $\w(p)$ between $p$ and $\n(p)$. That is, either $p$ is to the left of $\w(p)$ is to the left of $\n(p)$ or else the reverse is true. We can construct a directed graph $G=(P,E)$, where we interpret an edge $(a,b) \in E$ to represent the statement `player $a$ is to the left of player $b$ in an ordering of players'. 

    This says, transitively, that if there is a path from $a$ to $b$, then $a$ is to the left of $b$ (we will use $a \leadsto b$ to denote both of these). Notice that if these graphs actually represent an ordering of players, they do not contain cycles. For example, when both $(a,b)$ and $(b,a)$ are in $E$, this says $a \leadsto b$ and $b \leadsto a$, which is a contradiction. 

    \begin{thm}
    A Ninja Assassin Wonderwall problem has a solution iff there is a directed acyclic graph $G=(P,E)$ such that, for all $p\in P$, either  $p \leadsto \w(p) \leadsto \n(p)$ or $\n(p) \leadsto \w(p) \leadsto p$.
    \end{thm}
    \begin{proof} \mbox{}

    \begin{description}
    \item[$(\Rightarrow)$] Let $\phi: P \to \mathbb{R}$ be a solution to a Ninja Assassin Wonderwall problem. Construct a graph $G$ with an edge $(p,q)$ whenever $\phi(p)<\phi(q)$. By construction, $G$ is acyclic (in fact it is an ordered graph).

    Consider an arbitrary player $p$. Since $\phi$ is a solution, $\phi(\w(p))$ must be between $\phi(p)$ and $\phi(\n(p))$. So either $\phi(p) < \phi(\w(p)) < \phi(\n(p))$ or $\phi(\n(p)) < \phi(\w(p)) < \phi(p)$. Then either $p \leadsto \w(p) \leadsto \n(p)$ or $\n(p) \leadsto \w(p) \leadsto p$.

    \item[$(\Leftarrow)$] Let $G$ be such a graph. Let $\{p_i\}$ be a topological ordering of $G$. Define $\phi(p_i) = i$. 

    Let $p_i$ be an arbitrary player. By assumption, either $p_i \leadsto \w(p_i) \leadsto \n(p_i)$ or $\n(p_i) \leadsto \w(p_i) \leadsto p_i$. Without loss of generality, $p_i \leadsto \w(p_i) \leadsto \n(p_i)$. Since $\{p_i\}$ is a topological sort on $G$, $p_i$ must come before $\w(p_i)$, which must come before $\n(p_i)$. So $\phi(p_i) < \phi(\w(p_i)) < \phi(\n(p_i))$. Thus, $\phi$ is a solution to a Ninja Assassin Wonderwall problem.
    \end{description}
    \end{proof}

    This proof leads to an algorithm for constructing solutions. Consider the set $D$ of all digraphs $G=(P,E)$, where $E$ is constructed by taking, for all $p \in P$, either  $(p,\w(p)), (\w(p),\n(p))$ or $(\n(p),\w(p)),(\w(p),p)$. There are $2^n$ such graphs, and if a NAWW problem has a solution, one of them must be acyclic. Furthermore, the solution will be given by a Topological Sort of that graph. (A Topological Sort on a directed acyclic graph is an ordering that puts vertex $a$ before every vertex to which $a$ has outgoing edges.)

    \begin{codebox}
    \Procname{$\proc{FindOrdering}(P,n,w)$}
    \li \For $G\in D$
    \li     \Do
            \If $G$ is acyclic
    \li         \Do
                    \Return $\proc{TopologicalSort}(G)$
            \End
        \End
    \li \Return None
    \end{codebox}
        
    There are many small efficiencies we can add to this algorithm. We can avoid enumerating all the elements of $D$ by trying to construct our graph from scratch. We will start with an empty graph $G$. Then we will choose a $p \in P$, add the edges $(p,\w(p))$ and $(\w(p),\n(p))$ and recurse. If this leads to a cyclic graph, we will try the opposite edges and recurse. If \emph{this} leads to a cyclic graph, then neither $p \leadsto \w(p) \leadsto \n(p)$ nor $\n(p) \leadsto \w(p) \leadsto p$ is consistent with the graph, and so there is no solution.

    \begin{codebox}
    \Procname{$\proc{FindOrdering}(P,n,w)$}
    \li $G \gets (\emptyset, \emptyset)$
    \li $S \gets P$ \> \Comment $S$ is the players whose constraints have yet to be considered
    \li $G \gets \proc{MakeAssumption}(G,S,n,w)$
    \li \If $G$ is acyclic
    \li     \Do
            \Return $\proc{TopologicalSort}(G)$
        \End
    \li \Return None
    \end{codebox}


    \begin{codebox}
    \Procname{$\proc{MakeAssumption}(G,S,\n,\w)$}
    \li \If $S \isequal \emptyset$
    \li     \Then
            \Return $G$ \Comment Success!
        \End
    \li \If $G$ contains a cycle
    \li     \Then
            \Return $G$ \Comment Failure case
        \End
    \li Let $p \in S$
    \li $F \gets G$
    \li Add $(p,\w(p))$ and $(\w(p),\n(p))$ to the edgeset of $F$.
    %\li $\attrib{F}{E} \gets \attrib{F}{E} \cup \{(p,\w(p)), (\w(p),\n(p))\}$
    \li $F \gets \proc{MakeAssumption}(F,S\setminus \{p\}, \n, \w)$
    \li \If $F$ is acyclic
    \li     \Do
            \Return $F$ \Comment Success!
        \End
    \li $F \gets G$ \Comment That didn't work, try the other way.
    \li Add $(\n(p),\w(p))$ and $(\w(p),p)$ to the edgeset of $F$.
    %\li $\attrib{F}{E} \gets \attrib{F}{E} \cup \{(\n(p), \w(p)), (\w(p),p)\}$
    \li \Return $\proc{MakeAssumption}(F,S\setminus \{p\}, \n, \w)$ \Comment acyclic or not, this is our best shot.
    \end{codebox}

    We can make another small improvement by noticing that if $a \leadsto b$ where $a,b \in \{p, \w(p), \n(p)\}$ for some $p$, is already in the graph, then we can add the third element of $\{p, \w(p), \n(p)\}$ immediately. For example if $p \leadsto \n(p)$, then if $G$ is a subgraph of the acyclic graph in the theorem, $p \leadsto \w(p)$ and $\w(p) \leadsto \n(p)$. Edges that we can infer in this way are called `implied edges' in the pseudocode. We will use the same definition of $\proc{FindOrdering}$.

    \begin{codebox}
    \Procname{$\proc{MakeAssumption}(G,S,\n,\w)$}
    \li \If $S = \emptyset$
    \li \Do \Return $G$ \Comment Success!
        \End
    \li \If $G$ contains a cycle
    \li     \Then
            \Return $G$ \Comment Failure case
        \End
    \li Let $p \in S$.  			\label{li:choose-p}
    \li $F \gets G$
    \li $F \gets \proc{AddImpliedEdges}(F, (p,\w(p)), S,\n,\w)$
    \li $F \gets \proc{MakeAssumption}(F,S\setminus \{p\}, \n, \w)$
    \li \If $F$ is acyclic
    \li     \Do
            \Return $F$ \Comment Success!
        \End
    \li $F \gets G$ \Comment That didn't work, try the other way.
    \li $F \gets \proc{AddImpliedEdges}(F, (\w(p), p), S, \n, \w)$
    \li \Return $\proc{MakeAssumption}(F,S\setminus \{p\}, \n, \w)$ \Comment acyclic or not, this is our best shot.
    \end{codebox}


    \begin{codebox}
    \Procname{$\proc{AddImpliedEdges}(F,(a,b),S,\n,\w)$}
    \li $Q \gets \emptyset$
    \li $\proc{Enqueue}(Q,(a,b))$
    \li \While $Q$ is not empty
    \li     \Do
            $(r,s) \gets \proc{Dequeue}(Q)$
    \li      Add $(r,s)$ to the edgeset of $F$.
    %\li     $\attrib{F}{E} \gets \attrib{F}{E} \cup \{(r,s)\}$
    \li     \For $(t,u) \in \proc{ImpliedEdges}((r,s),S,\n,\w)$
    \li         \Do
                \If $(t,u) \notin \attrib{F}{E}$
    \li             \Do
                    Add $(t,u)$ to the edgeset of $F$.
                    %$\attrib{F}{E} \gets \attrib{F}{E} \cup \{(t,u)\}$
    \li             $\proc{Enqueue}(Q,(t,u))$
                \End
            \End
        \End
    \li \Return $F$
    \end{codebox}



    \begin{codebox}
    \Procname{$\proc{ImpliedEdges}((r,s),S,\n,\w)$}
    \li $E \gets \emptyset$
    \li \For $t \in S$
    \li     \Do
            \If $(r,s) \isequal (t, \w(t))$
    \li         \Do
                $E \gets E \cup \{(\w(t),\n(t)), (t, \n(t))\}$
    \li     \ElseIf $(r,s) \isequal (\w(t), t)$
    \li         \Do
                $E \gets E \cup \{(\n(t),\w(t)), (\n(t), t)\}$ 
    \li     \ElseIf $(r,s) \isequal (t, \n(t))$
    \li         \Do
                $E \gets E \cup \{(t,\w(t)), (\w(t), \n(t))\}$
    \li     \ElseIf $(r,s) \isequal (\n(t), t)$
    \li         \Do
                $E \gets E \cup \{(\w(t), t), (\n(t), \w(t))\}$
    \li     \ElseIf $(r,s) \isequal (\w(t), \n(t))$
    \li         \Do
                $E \gets E \cup \{(t,\w(t)), (t, \n(t))\}$
    \li     \ElseIf $(r,s) \isequal (\n(t), \w(t))$
    \li         \Do
                $E \gets E \cup \{(\w(t), t), (\n(t), t)\}$
            \End
        \End
    \li \Return $E$
    \end{codebox}

    Finally, notice that every \emph{implied edge} we add potentially cuts our running time in half. We no longer need a tree of $2^{\lvert S \rvert}$ recursive calls to determine the direction of that player's constraint. Each edge we add that has an \emph{implied edge} gives us some extra leverage over the problem. Heuristically, it seems like we should exert this leverage as early as possible. We accomplish this by choosing our $p\in S$ on line~\ref{li:choose-p} of \proc{MakeAssumption} such that the set $\{p,\w(p), \n(p)\}$ shares two elements with as many $\{t, \w(t), \n(t)\}, t\in S$ as possible. 

    In fact, we get the first choice we make for free. Since for any solution, the reverse of that permutation is also a solution, it doesn't matter which way we direct the edges of the first player we consider.

\section{Example trace of algorithm}
    We will walk through the logic of the algorithm for a small game:

    \begin{center}
        \begin{tabular}{ l | c | c}
         $p$ & $\w(p)$ & $\n(p)$ \\
         \hline
          A &  E& C\\
          B &  E& D\\
          C &  D& E\\
          D &  E& B\\
          E &  D& C\\
          F &  B& A
        \end{tabular} %assume D->E, assume A->B.
    \end{center}
    \begin{comment}
 Assume E -> D
  E -> D is given, so player B's choices give B -> D
  E -> D is given, so player B's choices give B -> E
  E -> D is given, so player C's choices give E -> C
  E -> D is given, so player C's choices give D -> C
  E -> D is given, so player D's choices give B -> D
  E -> D is given, so player D's choices give B -> E
  E -> D is given, so player E's choices give E -> C
  E -> D is given, so player E's choices give D -> C
  D -> C is given, so player C's choices give E -> C
  D -> C is given, so player C's choices give E -> D
  D -> C is given, so player E's choices give E -> C
  D -> C is given, so player E's choices give E -> D
  E -> C is given, so player A's choices give A -> C
  E -> C is given, so player A's choices give A -> E
  E -> C is given, so player E's choices give D -> C
  E -> C is given, so player E's choices give E -> D
  D -> C is given, so player E's choices give E -> C
  D -> C is given, so player E's choices give E -> D
  Assume F -> B
    F -> B is given, so player F's choices give F -> A
    F -> B is given, so player F's choices give B -> A
    No more players to try, and G is acyclic: Success!
F B A E D C
\end{comment}


    First, suppose $A \leadsto B$. We choose the pair $A$ and $B$ because that pair is tied (with $B$ and $C$) for the most common pair among all unordered pairs appearing among all triplets $(p, \w(p), \n(p))$. Immediately, we can use player $A$'s choice to infer more information. Since we have assumed $A$ is to the left of $B$, then $B$ must be to the left of $C$ or else $A$'s constraints won't be satisfied. This produces the graph below.
    \begin{center}
    \includegraphics[width=\textwidth]{alg2ex1.pdf}
    \end{center}
    Now, we can use the relationship table to make inferences of the same flavor. 
    \begin{itemize}
        \item We know $B \leadsto C$, so $B$'s constraint imposes that $C \leadsto D$.
        \item We know $A \leadsto B$, so by $C$'s constraint, $B \leadsto C$ (which we already knew).
        \item We know $A \leadsto B$, so by $D$'s constraint, $B \leadsto D$.
    \end{itemize}
    This produces the graph below.
    \begin{center}
    \includegraphics[width=\textwidth]{alg2ex3.pdf}
    \end{center}
    Now we've exhausted all the player constraints, and the graph is acyclic! A topological sort will give a valid ordering of $\langle A, B, C, D \rangle$.

    An example of a game without a solution is given in the next section.

\section{Running time of algorithm}
    The first algorithm described examines each digraph $G$ in $D$, checking each to see if it is acyclic. Since the check for acyclic takes $O(n)$ time where $n$ is the number of players, the whole algorithm takes $O(\lvert D \rvert \cdot n)$ time. 

    So what is $\lvert D \rvert$? We're constructing the edgeset by taking each row $(p, \w(p), \n(p))$ and directing it to the left or right. So an element of $D$ for a particular relationship table is uniquely identified by a bitstring of length $n$, $01011\ldots$, where a $0$ in the $i^{\text{th}}$ row indicates direction to left and a $1$ indicates direction to the right. There are $2^n$ such bitstrings, so $\lvert D \rvert = 2^n$. This first algorithm then, takes $O(n \cdot 2^n)$ time in the worst case. 

    It is not immediately clear what the running time of the heuristic algorithm is. The average case running time would be very hard to justify, as the heuristic muddies the water a fair bit. However, we will see that the worst case running time remains exponential.

    We will set a trap for the algorithm, a class of problem designed to afford no leverage to the heuristic. We will seek to confound the main improvement of the heuristic algorithm: extrapolating extra edge information each time it directs a pair. 

    The following could be considered a template for a relationship table, where we would want to replace each of $a, b, c, \text{ and }d$ with actual player names.

    \begin{center}
        \begin{tabular}{c | c | c}
            $p$ & $\w(p)$ & $\n(p)$\\
            \hline
            $a$ & $b$ & $c$\\
            $b$ & $c$ & $d$\\
            $c$ & $b$ & $a$\\
            $d$ & \_ & \_
        \end{tabular}
    \end{center}

    We could repeat this pattern indefinitely, making an arbitrarily large game. The very last instance of the template would replace $d \quad \_ \quad \_$ with $d \quad a \quad b$, ensuring a contradiction within that group. For example, here is a game with three copies of that structure:

    \begin{center}
        \begin{tabular}{c | c | c}
            $p$ & $\w(p)$ & $\n(p)$\\
            \hline
            $A$ & $B$ & $C$\\
            $B$ & $C$ & $D$\\
            $C$ & $B$ & $A$\\
            \hline
            $D$ & $E$ & $F$\\
            $E$ & $F$ & $G$\\
            $F$ & $E$ & $D$\\
            \hline
            $G$ & $H$ & $I$\\
            $H$ & $I$ & $J$\\
            $I$ & $H$ & $G$\\
            $J$ & $G$ & $H$
        \end{tabular}
    \end{center}

    Notice how each group of four players is `self-contained'. The choices of players $A,B,C$ contain no player other than $A,B,C, \text{ and } D$; the choices of players $D, E, F$ contain no player other than $D, E, F, \text{ and } G$. The overlap is just enough so that the games are not disjoint. This means that any leverage gained via the heuristic will not escape the four player group.

    For example, if the algorithm assumes that $A \leadsto D$, this information is useless as soon as we're addressing players other than $A,B,C,D$.

    Here is an example trace of the program, applied to the small example above:
    \begin{verbatimtab}
Suppose B -> C:
    We know B->C, and (A,B,C) is a triplet, so A->B, A->C.
    We know B->C, and (B,C,D) is a triplet, so C->D, B->D.
    Suppose E->F:
        We know E->F, and (D,E,F) is a triplet, so D->E, D->F.
        We know E->F, and (E,F,G) is a triplet, so F->G, E->G.
        Suppose H->I:
            We know H->I, and (G,H,I) is a triplet, so G->H, G->I.
            We know H->I, and (H,I,J) is a triplet, so I->J, H->J.
            We know G->H, and (J,G,H) is a triplet, so J->G, J->H.
            H->J and J->H form a cycle, so our assumption was wrong.
        Suppose I->H:
            We know I->H, and (G,H,I) is a triplet, so H->G, I->G.
            We know I->H, and (H,I,J) is a triplet, so J->I, J->H.
            We know H->G, and (J,G,H) is a triplet, so G->J, H->J.
            H->J and J->H form a cycle, so our assumption was wrong.
    Suppose F->E:
        We know F->E, and (D,E,F) is a triplet, so E->D, F->D.
        We know F->E, and (E,F,G) is a triplet, so G->F, G->E.
        Suppose H->I:
            We know H->I, and (G,H,I) is a triplet, so G->H, G->I.
            We know H->I, and (H,I,J) is a triplet, so I->J, H->J.
            We know G->H, and (J,G,H) is a triplet, so J->G, J->H.
            H->J and J->H form a cycle, so our assumption was wrong.
        Suppose I->H:
            We know I->H, and (G,H,I) is a triplet, so H->G, I->G.
            We know I->H, and (H,I,J) is a triplet, so J->I, J->H.
            We know H->G, and (J,G,H) is a triplet, so G->J, H->J.
            H->J and J->H form a cycle, so our assumption was wrong.
Suppose C->B:
    We know C->B, and (A,B,C) is a triplet, so B->A, C->A.
    We know C->B, and (B,C,D) is a triplet, so D->C, D->B.
    Suppose E->F:
        We know E->F, and (D,E,F) is a triplet, so D->E, D->F.
        We know E->F, and (E,F,G) is a triplet, so F->G, E->G.
        Suppose H->I:
            We know H->I, and (G,H,I) is a triplet, so G->H, G->I.
            We know H->I, and (H,I,J) is a triplet, so I->J, H->J.
            We know G->H, and (J,G,H) is a triplet, so J->G, J->H.
            H->J and J->H form a cycle, so our assumption was wrong.
        Suppose I->H:
            We know I->H, and (G,H,I) is a triplet, so H->G, I->G.
            We know I->H, and (H,I,J) is a triplet, so J->I, J->H.
            We know H->G, and (J,G,H) is a triplet, so G->J, H->J.
            H->J and J->H form a cycle, so our assumption was wrong.
    Suppose F->E:
        We know F->E, and (D,E,F) is a triplet, so E->D, F->D.
        We know F->E, and (E,F,G) is a triplet, so G->F, G->E.
        Suppose H->I:
            We know H->I, and (G,H,I) is a triplet, so G->H, G->I.
            We know H->I, and (H,I,J) is a triplet, so I->J, H->J.
            We know G->H, and (J,G,H) is a triplet, so J->G, J->H.
            H->J and J->H form a cycle, so our assumption was wrong.
        Suppose I->H:
            We know I->H, and (G,H,I) is a triplet, so H->G, I->G.
            We know I->H, and (H,I,J) is a triplet, so J->I, J->H.
            We know H->G, and (J,G,H) is a triplet, so G->J, H->J.
            H->J and J->H form a cycle, so our assumption was wrong.
    \end{verbatimtab}

    This demonstrates the fact that the algorithm will have to backtrack and reverse each assumption it makes upon reaching the cycle at the end. Since it will make one assumption for each group of three players, the running time will be $O(n \cdot 2^{n/3})$, which is exponential. 

    This is a worst case analysis, and in practice the running times are often much better than this. We have presented a pathological case in order to show that this algorithm has not beaten the exponential bound.

\begin{comment}
\section{Overview: Steiner Triple Systems}
    Definition, examples
    discuss how the number of pairs dominates the number of players
    (this defeats our heuristic)
    A slightly better algorithm could `outsmart' our trap from the previous section, but the existence of Steiner Triple Systems shows that we can have so few repeated pairs as to render the heuristic useless. STS shows that this is a systemic problem. 
\end{comment}

\section{Proportion of solvable games}
    \label{sec:prob}
    We are curious about, for a fixed $n$, what proportion of Ninja Assassin Wonderwall game have a solution. 

    First, how many games exist of a given size? A game depends on the independent choices of all $n$ players. Each player chooses a wonderwall and a ninja assassin from the other $n-1$ players. This means each player can has $2\cdot \binom{n-1}{2}$ ways to assign these roles. So the total number of games is $\displaystyle \left(2 \cdot \binom{n-1}{2}\right)^n$. This grows almost unimaginably quickly. 
    \begin{center}
        \begin{tabular}{c | r}
        $n$ & $\displaystyle \left(2 \cdot \binom{n-1}{2}\right)^n$\\
        \hline
        3 & 8\\
        4 & 1296 \\
        5 & 248832 \\
        6 & 64000000\\
        $\vdots$ & $\vdots$ \\
        10 & 3743906242624487424
        \end{tabular}
    \end{center}
    This probably too many to enumerate for anything over $n=6$, so we will approximate the proportion with a random sample. Even so, we've seen that our algorithm is $O(n\cdot 2^n)$, if only in pathological cases. Running, say, 10000 trials for a number different sizes of game would take a long time.

    We can cheat a bit using distributed computing. I randomly drew a 10000 game sample for each size from 4 to 100, putting them all in a job queue. I wrote a python script to pull problems out of the queue and pass them to a C++ implementation of the algorithm described in section \ref{sec:algorithm}. The result -- solvable or not -- was pushed to a central server. 

    I spun up this python script on about 130 computers, with between 8-24 threads each, and obtained the results below. I was doing this over spring break, when the computers were mostly not in use.

    \begin{center}
    \includegraphics[width=0.8\textwidth]{probplot.png}
    \end{center}

    It seems that the likelihood a game having a solution increases very quickly in the number of players.

    We didn't get quite all the way to $n=100$. Around $n=90$ the processes start to really drag. Also, spring break had ended and I needed to give back some computing resources. I recieved a message from Matthew Mooney, a student in the Computer Science department:
    \begin{quote}
    Hey, did you know you have a process running on cf416-14 that's using 99\% of the CPU? Not a big deal as I can just switch PCs, but thought you might want to know.
    \end{quote}
    And then, a few minutes later:
    \begin{quote}
    k I take that back. On my end at least, it looks like that process is running on multiple computers (maybe all? I've checked 3). Any idea what's up?
    \end{quote}

    It seemed polite to stop the simulation at this point.

\section{Future work}
    We have danced around the question of NP-Completeness in this paper. It would be good to determine whether or not Ninja Assassin Wonderwall is NP-Complete. If it is, we should provide a proof. If not, perhaps we can find a polynomial time algorithm.

    The algorithm depends on knowing all of the relationships among the players. It would be interesting to model the way people play the game. How can players with incomplete knowledge find solutions?

    Some games are `isomorphic'. It is possible that the number of non-isomorphic games is much smaller than the number of total games. and we could have a hope of enumerating them. For example, in the tables below the roles of $B$ and $C$ have been swapped. These two games will behave identically-- if one is solvable then the other is as well. A solution for one can be used to create a solution for the other just by swapping $B$ and $C$.

    \begin{multicols}{2}
        \begin{tabular}{l | c | c}
             $p$ & $\w(p)$ & $\n(p)$ \\
             \hline
             A &  C& B\\
             B &  D& A\\
             C &  D& A\\
             D &  C& E\\
             E &  A& B\\
        \end{tabular}


        \columnbreak
        \begin{tabular}{l | c | c}
             $p$ & $\w(p)$ & $\n(p)$ \\
             \hline
             A &  B& C\\
             B &  D& A\\
             C &  D& A\\
             D &  B& E\\
             E &  A& C\\
        \end{tabular}
    \end{multicols}


\section{Appendix: code}
    \renewcommand{\ttdefault}{pcr}
    \lstset{basicstyle=\footnotesize\ttfamily,
        commentstyle=\color{mygreen},
        keywordstyle=\bfseries\color{blue},
        numbers=left,
        numbersep=5pt,
        numberstyle=\tiny\color{mygray},
        stepnumber=5,
        stringstyle=\color{mymauve},
        showstringspaces=false,
        tabsize=2}
    \subsection{Haskell brute force algorithm}
        This is very obviously an $O(n!)$ algorithm. I used it to check my ideas and generate small examples of solvable and unsolveable games. It also provided a check that the more complicated algorithms were working correctly.
        \lstinputlisting[language=Haskell,breaklines=true]{../na_ww_brute.hs}
    \subsection{Python implementation}
        This was the first implementation of the algorithm described in section \ref{sec:algorithm}. It works fairly well, but is noticeably much slower than the C++ implementation. However, the networkx graph library is \emph{much} more friendly than the Boost Graph Library that I used for C++.
        \lstinputlisting[language=Python,
        breakatwhitespace=false,
        breaklines=true]{../implication.py}
    \subsection{C++ implementation}
        I created this implementation in order to do the distributed trials described in section \ref{sec:prob}. It is more faithfull to the pseudocode in section \ref{sec:algorithm} than the python code, but it also has some ugliness introduced by the the Boost Graph Library and a few tasks that are harder to phrase in C++ than Python (for example, sorting the player on their pair count is on lines 184-235 of the C++ code, and lines 103-112 of the Python code).
        \lstinputlisting[language=C++]{../cpp_implementation/implication.cpp}
    \subsection{Python driver}
        This is the driver mentioned in section \ref{sec:prob} that pulls Ninja Assassin Wonderwall problems from the jobs queue, spins up the C++ code to solve them, and then updates the server with the result.
        \lstinputlisting[language=Python, breakatwhitespace=false,
        breaklines=true]{../cpp_implementation/naww_client.py}

\begin{thebibliography}{9}

\bibitem{stinson}
    Douglas R. Stinson
    \emph{Combinatorial Designs: Constructions and Analysis}.
    Springer, New York,
    2004 edition.

\bibitem{cameron}
    Peter J. Cameron
    \emph{Combinatorics: Topics, Techniques, Algorithms}.
    Cambridge University Press,
    1995 edition.

\bibitem{clrs}
    T.~H. Cormen, C.~E. Leiserson, R.~L. Rivest, and C.~Stein
    \emph{Introduction to Algorithms}.
    The MIT Press,
    2009 edition.


\end{thebibliography}

\end{document}